==============================================================================
./moonship/codecacher.moon
==============================================================================

 3 aws_auth         = require "mooncrafts.awsauth"
 3 httpc            = require "mooncrafts.http"
 3 sandbox          = require "mooncrafts.sandbox"
 3 util             = require "mooncrafts.util"

 3 lfs              = require "lfs"
 3 lru              = require "lru"
 3 plpath           = require "path"
 3 log              = require "mooncrafts.log"
*0 fs               = require "path.fs"

 3 local *

 4 mkdirp = (p) ->
 4   fs.makedirs p

 8 myUrlHandler = (opts) ->
     -- ngx.log(ngx.ERR, "mydebug: " .. secret_key)
*0   cleanPath, querystring  = string.match(opts.url, "([^?#]*)(.*)")
*0   full_path               = util.path_sanitize(cleanPath)
*0   authHeaders             = {}
*0   full_path               = util.path_sanitize("#{full_path}/index.moon")

 4   if opts.aws and opts.aws.aws_s3_code_path
       -- process s3 stuff
 4     opts.aws.request_path = "/#{opts.aws.aws_s3_path}/#{full_path}"
 4     aws = aws_auth(opts.aws)
 4     full_path = "https://#{aws.options.aws_host}#{opts.aws.request_path}"
*0     authHeaders = aws\get_auth_headers()
     else
 4     full_path = "#{opts.remote_path}/#{full_path}"

 4   log.debug "code load: #{full_path}"

*0   req = { url: full_path, method: "GET", capture_url: "/__libprivate", headers: {} }
 4   req.headers["If-Modified-Since"] = opts.last_modified if opts.last_modified

*0   for k, v in pairs(authHeaders) do
 4     req.headers[k] = v

     -- ngx.log(ngx.ERR, 'req' .. util.to_json(req))
*0   res, err = httpc.request(req)

     -- ngx.log(ngx.ERR, 'res' .. util.to_json(res))
*0   return res unless err

*0   log.debug "code load error: #{err}"

*0   { code: 0, body: err }

   --
   -- the strategy of this cache is to:
   --1. dynamically load remote file
   --2. cache it locally
   --3. use local file to trigger cache purge
   --4. use ttl (in seconds) to determine how often to check remote file
   -- when we have the file, it is recommended to check every hour
   -- when we don't have the file, check every x seconds - limit by proxy
   class CodeCacher

*0   new: (opts={}) =>
*0     defOpts = {app_path: "/app", ttl: 3600, codeHandler: myUrlHandler, code_cache_size: 10000}
 3     util.applyDefaults(opts, defOpts)

       -- should not be lower than 2 minutes
       -- user should use cache clearing mechanism
 2     opts.ttl = 120 if (opts.ttl < 120)

 2     opts.localBasePath = plpath.abs(opts.app_path)

 2     opts["sandbox_env"] = sandbox.build_env(_G, opts.plugins, sandbox.whitelist)
 2     @codeCache = lru.new(opts.code_cache_size)
 2     @options = opts

   --
   --if value holder is nil, initialize value holder
   --if value is nil or ttl has expired
   -- load File if it exists
     -- set cache for next guy
     -- set fileModification DateTime
   -- doCheckRemoteFile()
     -- if remote return 200
       -- write file, load data
     -- on 404 - delete local file, set nil
     -- on other error - do nothing
   -- remove from cache if not found
   -- return result function

   --NOTE: urlHandler should use capture to simulate debounce

 3   doCheckRemoteFile: (valHolder, aws) =>
 3     opts = {
 3       url: valHolder.url,
 3       remote_path: @options.remote_path
 3     }

 3     opts["last_modified"] = os.date("%c", valHolder.fileMod) if (valHolder.fileMod ~= nil)

       -- copy over aws options
 3     unless opts.remote_path
 3       opts.aws = aws

       -- if remote return 200
*0     rsp, err = @options.codeHandler(opts)

       -- ngx.log(ngx.INFO, 'rsp' .. util.to_json(rsp))
       -- ngx.log(ngx.INFO, 'err: ' .. util.to_json(err))

 4     if (rsp.code == 200)
         -- ngx.say(valHolder.localPath)
         -- write file, load data
         -- ngx.log(ngx.ERR, opts)
 1       if (rsp.body)
*0         lua_src = sandbox.compile_moon rsp.body
 3         if (lua_src)
*0           mkdirp(valHolder.localPath)
 3           file = io.open(valHolder.localFullPath, "w")
 1           if file
*0             file\write(lua_src)
 3             file\close()

*0             valHolder.fileMod = lfs.attributes valHolder.localFullPath, "modification"
 1             valHolder.value = sandbox.loadstring_safe lua_src, valHolder.localFullPath, @options.sandbox_env

*0     elseif (rsp.code == 404)
         -- on 404 - set nil and delete local file
 6       valHolder.value = nil
*0       os.remove(valHolder.localFullPath)

*0   get: (aws) =>
*0     req = @options.plugins["request"]
 3     req.cb = req.cb or ""
*0     @options.sandbox_env.request = req
*0     url = util.path_sanitize("#{req.host}/#{req.path}")
 3     valHolder = @codeCache\get(url .. "#{req.cb}")

       -- initialize valHolder
 3     unless valHolder
         -- strip query string and http/https://
*0       domainAndPath, query = string.match(url, "([^?#]*)(.*)")
*0       domainAndPath = string.gsub(string.gsub(domainAndPath, "http://", ""), "https://", "")

         -- expect directory
 6       fileBasePath = util.path_sanitize(@options.localBasePath .. "/" .. domainAndPath)

         -- must store locally as index.lua
         -- this way, a path can contain other paths
*0       localFullPath = fileBasePath .. "/index.lua"

 3       valHolder = {
*0         url: url,
 3         localPath: fileBasePath,
 3         localFullPath: localFullPath,
 3         lastCheck: os.time(),
 3         fileMod: lfs.attributes localFullPath, "modification"
 3       }

         -- use aws s3 if available
*0       valHolder["aws"] = @options.aws if (@options.aws)

 3     if (valHolder.value == nil or (valHolder.lastCheck < (os.time() - @options.ttl)))
         -- load file if it exists
 3       valHolder.fileMod = lfs.attributes valHolder.localFullPath, "modification"
*0       if valHolder.fileMod
*0         log.debug tostring(valHolder.fileMod)

*0         valHolder.value = sandbox.loadfile_safe valHolder.localFullPath, @options.sandbox_env

           -- set it back immediately for the next guy
           -- set next ttl
*0         valHolder.lastCheck = os.time()
*0         @codeCache\set url .. "#{req.cb}", valHolder
         else
           -- delete reference if file no longer exists/purged
*0         valHolder.value = nil

*0       @doCheckRemoteFile(valHolder, aws)

       -- remove from cache if not found
*0     @codeCache\delete(url .. "#{req.cb}") if valHolder.value == nil
*0     return sandbox.exec(valHolder.value) if (type(valHolder.value) == "function")

       valHolder.value

*0 { :CodeCacher, :myUrlHandler }

==============================================================================
./moonship/config.moon
==============================================================================

 2 util                  = require "mooncrafts.util"
 2 log                   = require "mooncrafts.log"
 2 sandbox               = require "mooncrafts.sandbox"
 2 remoteresolver        = require "mooncrafts.remoteresolver"
 2 requestbuilder        = require "mooncrafts.requestbuilder"
 2 asynclogger           = require "mooncrafts.asynclogger"

 2 aws_region            = os.getenv("AWS_DEFAULT_REGION") or "us-east-1"
 2 aws_access_key_id     = os.getenv("AWS_S3_KEY_ID")
 2 aws_secret_access_key = os.getenv("AWS_S3_ACCESS_KEY")
 2 aws_s3_code_path      = os.getenv("AWS_S3_CODE_PATH") -- 'bucket-name/basepath'
 2 azure_storage         = os.getenv("AZURE_STORAGE") or ""

 2 app_path              = os.getenv("MOONSHIP_APP_PATH")
 2 app_env               = os.getenv("MOONSHIP_APP_ENV") or "PRD"

 2 code_cache_size       = os.getenv("MOONSHIP_CODE_CACHE_SIZE") or 10000

   -- use this in place of AWS
 2 remote_path           = os.getenv("MOONSHIP_REMOTE_PATH")

*0 import string_split, table_clone, string_connection_parse from util
*0 import insert from table
 4 import upper from string

*0 build_requires = (opts) ->
*0   (modname) ->
 4     mod = _G[modname]
 4     return mod if mod

 4     parsed = remoteresolver.resolve(modname, opts)

 4     if parsed._remotebase
 4       loadPath = "#{parsed._remotebase}/#{parsed.file}"

         -- log.error loadPath
 4       rsp = parsed.codeloader(loadPath)
 4       if (rsp.code == 200)
 4         lua_src, err = sandbox.compile_moon rsp.body

 8         return nil, "error compiling `#{modname}` with message: #{err}" unless lua_src

*0         fn, err = nil, nil

 4         opts.plugins._remotebase = parsed._remotebase
 8         opts.sandbox_env = sandbox.build_env(_G, opts.plugins, sandbox.whitelist)
 4         fn, err = sandbox.loadstring lua_src, modname, opts.sandbox_env

*0         return nil, "error loading `#{modname}` with message: #{err}" unless fn

 4         rst, err = sandbox.exec(fn)
*0         return nil, "error executing `#{modname}` with message: #{err}" unless rst

*0         _G[modname] = rst

 3         return rst

 2       nil, "error loading `#{modname}` with code: #{rsp.code }"

*0     _G[modname], "unable to resolve `#{modname}`"

   class Config
 7   new: (newOpts={}) =>
 2     defaultOpts = {
*0       :aws_region, :aws_access_key_id, :aws_secret_access_key, :aws_s3_code_path,
 2       :app_path, :code_cache_size, :remote_path, :azure_storage, :app_env, plugins: {}
 4     }

 3     util.applyDefaults(newOpts, defaultOpts)

*0     newOpts.alog = newOpts.azure_storage
       -- ngx.log(ngx.INFO, util.to_json(newOpts))

 3     newOpts.app_env = upper(newOpts.app_env or "PRD")
 3     newOpts.requestbuilder = newOpts.requestbuilder or requestbuilder()
 3     newOpts.plugins["require"] = newOpts.require or build_requires(newOpts)
 3     req = newOpts.requestbuilder\build()

       -- ngx.log(ngx.INFO, util.to_json(req))

 3     newOpts.plugins["request"] = req
 3     newOpts.plugins["log"] = req\log

       -- parsing azure storage connection string
 3     newOpts["azure"] = string_connection_parse(azure_storage or "")
 6     newOpts["alog"] = asynclogger({
 6       account_name: newOpts.azure.AccountName,
 6       account_key: newOpts.azure.AccountKey
 3     })

*0     @__data = newOpts

 3   get: () => table_clone(@__data, true) -- preserving config through cloning

   Config

==============================================================================
./moonship/engine.moon
==============================================================================
 2 config         = require "moonship.config"
 2 codecacher     = require "moonship.codecacher"
 2 util           = require "mooncrafts.util"
 2 log            = require "mooncrafts.log"
 2 Storage        = require "moonship.plugins.storage"

   -- response with
   -- :body, :code, :headers, :status, :error
 2 class Engine
*0   new: (opts) =>
 1     options = util.applyDefaults(opts, {})
*0     if (options.useS3)
*0       options.aws = {
*0         aws_access_key_id: options.aws_access_key_id,
*0         aws_secret_access_key: options.aws_secret_access_key,
*0         aws_s3_code_path: options.aws_s3_code_path
         }

*0     @options = config(options)
*0     @alog = @options\get().alog
 1     @codeCache = codecacher.CodeCacher(@options\get())

 1   handleResponse: (rst) =>
 1     return {body: rst, code: 500, status: "500 unexpected response", headers: {'Content-Type': "text/plain"}} if type(rst) ~= 'table'

*0     rst.code = rst.code or 200
 2     rst.headers = rst.headers or {}
 2     rst.headers["Content-Type"] = rst.headers["Content-Type"] or "text/plain"
 2     rst

 2   engage: (req) =>
 2     opts = @options\get()

 4     opts.plugins["request"] = req if req
*0     req = opts.plugins["request"]
 2     req.start = os.time()

       -- create storage and cache if not exists
 2     unless opts.plugins["storage"]
 2       opts.plugins["storage"] = Storage(opts, "storage")

*0     unless opts.plugins["cache"]
*0       opts.plugins["cache"] = Storage(opts, "cache")

*0     rst, err = @codeCache\get(opts)

*0     return { :req, error: err, code: 500, status: "500 Engine.engage error", headers: {}  } if err
*0     return { :req, code: 404, headers: {}  } unless rst

 1     @handleResponse(rst)
 1     rst.req = req
       rst

 1 Engine

==============================================================================
./moonship/plugins/storage.moon
==============================================================================
   -- implement storage with azure

 2 http    = require "mooncrafts.http"
 2 azt     = require "mooncrafts.aztable"
 2 util    = require "mooncrafts.util"

*0 import from_json, to_json from util

   class Storage
 2   azure = {}
*0   req = {}
*0   table_name = "storage"
*0   cache = {set: () -> , get: () -> }
*0   new: (opts, tableName="storage") =>
*0     req = opts.plugins.request
*0     azure = opts.azure
*0     table_name = tableName
*0     if ngx
*0       cache = ngx.shared["moonship#{tableName}"]

*0   get: (k) =>
       -- check 1st lvl cache
*0     realKey = "#{req.host}#{k}"
*0     val = cache\get(realKey)
*0     return val if val

*0     opts = azt.item_retrieve({
*0       tenant: "a",
*0       table_name: table_name,
*0       rk: k,
*0       pk: req.host
       })

 2     res = azt.request(opts, true)
*0     return nil, "#{k} not found" unless res.body

*0     rst = from_json(res.body)
*0     if (table_name\find("cache"))
*0       return nil, "#{k} not found" if (rst.ttlx < os.time())

       rst.v

*0   set: (k, v, ttl=600) =>
*0     vt = type v

*0     return nil, "value must be string" unless vt == "string"

*0     opts = azt.item_update({
*0       tenant: "a",
*0       table_name: table_name,
*0       rk: k,
*0       pk: req.host
*0     }, "MERGE")
*0     ttlx = os.time() + ttl

*0     opts.body = to_json({:v, :ttlx, :ttl, RowKey: opts.rk, PartitionKey: opts.pk})
*0     res = azt.request(opts, true)

*0     realKey = "#{req.host}#{k}"

       -- short 2 seconds prevent trigger of backend ddos filter
*0     cache\set(realKey, v, 2)

       -- return response
       res


   Storage

==============================================================================
Summary
==============================================================================

File                            Hits Missed Coverage
----------------------------------------------------
./moonship/codecacher.moon      54   40     57.45%
./moonship/config.moon          48   12     80.00%
./moonship/engine.moon          22   15     59.46%
./moonship/plugins/storage.moon 5    37     11.90%
----------------------------------------------------
Total                           129  104    55.36%
